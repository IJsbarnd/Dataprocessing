Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job               count    min threads    max threads
--------------  -------  -------------  -------------
all                   1              1              1
bcftools_call         1              1              1
bwa_map               2              1              1
getsamples            2              1              1
plot_quals            1              1              1
samtools_index        2              1              1
samtools_sort         2              1              1
total                11              1              1

Select jobs to execute...

[Wed Apr  6 12:06:59 2022]
Job 8: Executing fastq-dump with 1 threads on the following files {'SRR2073061': 'SRR2073061.fastq', 'SRR2073062': 'SRR2073062.fastq'}

[Wed Apr  6 12:06:59 2022]
Error in rule getsamples:
    jobid: 8
    output: /homes/ijapool/Thema/thema11/dataprocessing/Dataprocessing/Eindopdracht/Resources/data/SRR2073062.fastq
    log: logs/download_SRR2073062.log (check log file(s) for error message)
    shell:
        parallel-fastq-dump -t 1 -s {'SRR2073061': 'SRR2073061.fastq', 'SRR2073062': 'SRR2073062.fastq'} -O /homes/ijapool/Thema/thema11/dataprocessing/Dataprocessing/Eindopdracht/Resources/data/ 2> logs/download_SRR2073062.log
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /homes/ijapool/Thema/thema11/dataprocessing/Dataprocessing/Eindopdracht/Workflow/.snakemake/log/2022-04-06T120658.902182.snakemake.log
